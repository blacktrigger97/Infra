networks:
  bdCluster:
    name: bdCluster
    driver: ipvlan
    # external: true
    driver_opts:
      parent: ${ETHERNET_NAME}
    ipam:
      config:
        - subnet: 192.168.1.0/24
          ip_range: 192.168.1.0/24
          gateway: 192.168.1.1

volumes:
  cifs-volume:
    driver_opts:
      type: cifs
      o: nounix,rw
      device: //worker1.bdc.home/airflow

services:

  airflow:
    build:
      context: airflow
      dockerfile: ${HOST_DIR}/hdc/airflow/Dockerfile
      args:
        - AWS_SPARK=${AWS_SPARK}
        - COMMON_POOL_VER=${COMMON_POOL_VER}
        - ICEBERG_SPARK_VER=${ICEBERG_SPARK_VER}
        - ICEBERG_VER=${ICEBERG_VER}
        - KAFKA_CLIENT_VER=${KAFKA_CLIENT_VER}
        - NESSIE_SPARK_VER=${NESSIE_SPARK_VER}
        - NESSIE_VER=${NESSIE_VER}
        - SCALA_VERSION=${SCALA_VERSION}
        - SPARK_VERSION=${SPARK_VERSION}
        - SPARK_SQL_KAFKA_VER=${SPARK_SQL_KAFKA_VER}
        - DOCKER_USR=${DOCKER_USR}
        - DOCKER_PASS=${DOCKER_PASS}
        - DOCKER_DIR=${DOCKER_DIR}
        - AIRFLOW_VER=${AIRFLOW_VER}
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
    container_name: airflow
    hostname: airflow.bdc.home
    restart: unless-stopped
    networks:
      bdCluster:
        ipv4_address: 192.168.1.34
    ports:
      - 8080:8080
      - 5555:5555
      - 8794:8794
    environment:
      TZ: "Asia/Kolkata"
    volumes:
      # - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      # - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - /shares/airflow:/root/airflow:z

  name-res:
    build:
      context: name-res
      dockerfile: ${HOST_DIR}/hdc/name-res/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_NAMENODE_DIR=${NAMENODE_DIR}
        - LOCAL_NAMENODE_DIR=${NAMENODE_DIR}
    user: root
    image: name-res
    container_name: name-res
    restart: unless-stopped
    hostname: name-res.bdc.home
    cpus: 1
    networks:
      bdCluster:
        ipv4_address: 192.168.1.91
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 9870:9870
      - 8088:8088
      - 7077:7077
    environment:
      TZ: "Asia/Kolkata"
    volumes:
      - ${LOCAL_DIR}docker/${NAMENODE_DIR}:${DOCKER_DIR}${NAMENODE_DIR}
      # - ${LOCAL_DIR}logs/namenode1:${DOCKER_DIR}logs/hadoop
      - ${LOCAL_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      # - cifs-volume:/root/${AIRFLOW_DIR}:z

  data-node1:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node1
    restart: unless-stopped
    hostname: data-node1.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.101
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
      - 8793:8793
    environment:
      TZ: "Asia/Kolkata"
      # CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      # CELERY_BROKER_URL: redis://redis.bdc.home:6379/0
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}1:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node1:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

  data-node2:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node2
    restart: unless-stopped
    hostname: data-node2.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.102
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
      - 8793:8793
    environment:
      TZ: "Asia/Kolkata"
      # CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      # CELERY_BROKER_URL: redis://redis.bdc.home:6379/0  
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}2:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node2:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

  data-node3:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node3
    restart: unless-stopped
    hostname: data-node3.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.103
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
      - 8793:8793
    environment:
      TZ: "Asia/Kolkata"
      # CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      # CELERY_BROKER_URL: redis://redis.bdc.home:6379/0
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}3:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node2:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

