networks:
  bdCluster:
    name: bdCluster
    driver: ipvlan
    driver_opts:
      parent: ${ETHERNET_NAME}
    ipam:
      config:
        - subnet: 192.168.1.0/24
          ip_range: 192.168.1.0/24
          gateway: 192.168.1.1

volumes:
  cifs-volume:
    driver_opts:
      type: cifs
      o: nounix,rw
      device: //worker1.bdc.home/airflow

services:

  airflow:
    build:
      context: airflow
      dockerfile: ${HOST_DIR}/hdc/airflow/Dockerfile
      args:
        - DOCKER_USR=${DOCKER_USR}
        - DOCKER_PASS=${DOCKER_PASS}
        - DOCKER_DIR=${DOCKER_DIR}
        - AIRFLOW_VER=${AIRFLOW_VER}
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
    container_name: airflow
    hostname: airflow.bdc.home
    restart: unless-stopped
    networks:
      bdCluster:
        ipv4_address: 192.168.1.34
    ports:
      - 8080:8080
      - 5555:5555
    environment:
      TZ: "Asia/Kolkata"
      AIRFLOW__CORE__EXECUTOR: 'CeleryExecutor'
      AIRFLOW__CORE__DAGS_FOLDER: ${DOCKER_DIR}airflow/dags
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__SCHEDULER__CATCHUP_BY_DEFAULT : 'false'
      AIRFLOW__SCHEDULER__ALLOW_TRIGGER_IN_FUTURE: 'true'
      AIRFLOW__WEBSERVER__BASE_URL: http://airflow.bdc.home:8080
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: ${DOCKER_DIR}logs/airflow/
      AIRFLOW__LOGGING__DAG_PROCESSOR_MANAGER_LOG_LOCATION: ${DOCKER_DIR}logs/airflow/dag_processor_manager/dag_processor_manager.log
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      CELERY_BROKER_URL: redis://redis.bdc.home:6379/0
    volumes:
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - /mnt/dockerShare/airflow:/root/airflow:z

  name-res:
    build:
      context: name-res
      dockerfile: ${HOST_DIR}/hdc/name-res/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_NAMENODE_DIR=${NAMENODE_DIR}
        - LOCAL_NAMENODE_DIR=${NAMENODE_DIR}
    user: root
    image: name-res
    container_name: name-res
    restart: unless-stopped
    hostname: name-res.bdc.home
    cpus: 1
    networks:
      bdCluster:
        ipv4_address: 192.168.1.91
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 9870:9870
      - 8088:8088
      - 7077:7077
    environment:
      TZ: "Asia/Kolkata"
    volumes:
      - ${LOCAL_DIR}docker/${NAMENODE_DIR}:${DOCKER_DIR}${NAMENODE_DIR}
      # - ${LOCAL_DIR}logs/namenode1:${DOCKER_DIR}logs/hadoop
      - ${LOCAL_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      # - cifs-volume:/root/${AIRFLOW_DIR}:z

  data-node1:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node1
    restart: unless-stopped
    hostname: data-node1.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.101
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
    environment:
      TZ: "Asia/Kolkata"
      CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      CELERY_BROKER_URL: redis://redis.bdc.home:6379/0
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}1:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node1:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

  data-node2:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node2
    restart: unless-stopped
    hostname: data-node2.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.102
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
    environment:
      TZ: "Asia/Kolkata"
      CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      CELERY_BROKER_URL: redis://redis.bdc.home:6379/0  
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}2:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node2:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

  data-node3:
    build:
      context: data-node
      dockerfile: ${HOST_DIR}/hdc/data-node/Dockerfile
      args:
        - GIT_CONFIG_DIR=${GIT_CONFIG_DIR}
        - GIT_CONFIG_ADDRESS=${GIT_CONFIG_ADDRESS}
        - GIT_AIRFLOW_ADDRESS=${GIT_AIRFLOW_ADDRESS}
        - DOCKER_DIR=${DOCKER_DIR}
        - DOCKER_DATANODE_DIR=${DATANODE_DIR}
    user: root
    image: data-node
    container_name: data-node3
    restart: unless-stopped
    hostname: data-node3.bdc.home
    networks:
      bdCluster:
        ipv4_address: 192.168.1.103
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
    ports:
      - 8042:8042
    environment:
      TZ: "Asia/Kolkata"
      CELERY_RESULT_BACKEND: "db+postgresql://${DOCKER_USR}:${DOCKER_PASS}@postgresql.bdc.home/airflow"
      CELERY_BROKER_URL: redis://redis.bdc.home:6379/0
    volumes:
      - ${LOCAL_DIR}docker/${DATANODE_DIR}3:${DOCKER_DIR}${DATANODE_DIR}
      # - ${DOCKER_DIR}logs/data-node2:${DOCKER_DIR}logs/hadoop
      - ${DOCKER_DIR}hadoop:${DOCKER_DIR}hadoop:ro
      - ${DOCKER_DIR}spark:${DOCKER_DIR}spark:ro
      - cifs-volume:/root/airflow:z

